{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8049d6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import join\n",
    "import argparse\n",
    "import numpy as np\n",
    "from tqdm import trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee5083fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04efc77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import classifier\n",
    "import nn_ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2adcfb68",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(67)\n",
    "torch.manual_seed(67)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f54d421",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "N_IMAGES_TO_PLOT = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eea8434",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def main(args):\n",
    "  \n",
    "  if args.dataset == 'cifar10':\n",
    "    n_class = 10\n",
    "\n",
    "    test_transform = transforms.Compose([\n",
    "      transforms.ToTensor(), \n",
    "      transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "    ])\n",
    "    test_set = torchvision.datasets.CIFAR10(root=args.data_dir, train=False, download=True, transform=test_transform)\n",
    "    test_loader = torch.utils.data.DataLoader(test_set, batch_size=args.batch_size, shuffle=False, num_workers=4)\n",
    "\n",
    "  clf = classifier.ConvNet(n_class,\n",
    "                           device=args.device,\n",
    "                           ckpt_file=args.ckpt_file)\n",
    "  clf.net.eval()\n",
    "  for p in clf.net.parameters(): p.requires_grad = False                           \n",
    "\n",
    "  n_ch, sp_size = test_set[0][0].size()[:2]\n",
    "  n_features = clf.n_planes[-1]\n",
    "  n_images = len(test_set)\n",
    "\n",
    "  print ('Extracting features from the test set ... ')\n",
    "  test_features = torch.zeros(n_images, n_features, device='cpu')\n",
    "  for b_ix, (x, y) in enumerate(test_loader):\n",
    "    x = x.to(args.device)\n",
    "    ix_from = b_ix * args.batch_size\n",
    "    ix_to = ix_from + args.batch_size\n",
    "    test_features[ix_from:ix_to, :] = clf.net.features(x).to('cpu')\n",
    "  test_features = test_features.numpy()\n",
    "\n",
    "  print ('Selecting and ploting samples based on their feature magnitudes ... ')\n",
    "  images_to_save = torch.zeros(n_features * N_IMAGES_TO_PLOT, n_ch, sp_size, sp_size, device='cpu')\n",
    "  for f_ix in trange(n_features):\n",
    "    ranks = test_features[:, f_ix].argsort()\n",
    "    inds = np.hstack([ranks[:N_IMAGES_TO_PLOT//2], ranks[-N_IMAGES_TO_PLOT//2:]])\n",
    "\n",
    "    for im_ix in trange(N_IMAGES_TO_PLOT):\n",
    "      images_to_save[f_ix * N_IMAGES_TO_PLOT + im_ix, :, :, :] = test_set[inds[im_ix]][0]\n",
    "\n",
    "  torchvision.utils.save_image(\n",
    "    images_to_save,\n",
    "    join(args.log_dir, '%s_images_selected_by_features.png' % args.dataset), \n",
    "    N_IMAGES_TO_PLOT,\n",
    "    normalize=True)\n",
    "\n",
    "  torch.save(\n",
    "    {'images': images_to_save},\n",
    "    join(args.log_dir, '%s_images_selected_by_features.torch' % args.dataset)\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1214bd78",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "  parser = argparse.ArgumentParser()\n",
    "  parser.add_argument('--log_dir', type=str, default='./log')\n",
    "  parser.add_argument('--ckpt_file', type=str, default='./log/state_dict.ckpt')\n",
    "  parser.add_argument('--data_dir', type=str, default='./data')\n",
    "  parser.add_argument('--dataset', type=str, default='cifar10', choices=['cifar10'])\n",
    "  parser.add_argument('--device', type=str, default='cuda', choices=['cpu', 'cuda'])\n",
    "  parser.add_argument('--batch_size', type=int, default=100)\n",
    "  args = parser.parse_args()\n",
    "\n",
    "  main(args)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
